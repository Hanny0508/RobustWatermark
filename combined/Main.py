import os
import random
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import numpy as np
from torch.utils.data import Dataset, DataLoader
from torch.utils.tensorboard import SummaryWriter
from PIL import Image
from torchvision import transforms
import glob
import matplotlib.pyplot as plt
from tqdm import tqdm
import config as c  # å¯¼å…¥config


# å›ºå®šéšæœºç§å­ï¼ˆæå‡å¯å¤ç°æ€§ï¼‰
def set_seed(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False


set_seed(42)

# ===================== è®¾å¤‡é…ç½® =====================
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ä½¿ç”¨è®¾å¤‡: {DEVICE}")

# åˆ›å»ºè·¯å¾„ï¼ˆç¡®ä¿æ‰€æœ‰è·¯å¾„å­˜åœ¨ï¼‰
os.makedirs(c.CHECKPOINT_PATH, exist_ok=True)
os.makedirs(c.LOG_PATH, exist_ok=True)
os.makedirs(c.IMAGE_PATH_host, exist_ok=True)
os.makedirs(c.IMAGE_PATH_container, exist_ok=True)
os.makedirs(c.IMAGE_PATH_secret, exist_ok=True)
os.makedirs(c.IMAGE_PATH_extracted, exist_ok=True)
os.makedirs(c.IMAGE_PATH_combined, exist_ok=True)  # æ–°å¢ï¼šæ‹¼æ¥å¯¹æ¯”å›¾è·¯å¾„


# ===================== å·¥å…·å‡½æ•° =====================
def PSNR(x, y):
    """è®¡ç®—PSNRï¼ˆæ‰¹æ¬¡çº§ï¼Œè¿”å›å¼ é‡ï¼‰"""
    x = x.clamp(0, 1)
    y = y.clamp(0, 1)
    mse = F.mse_loss(x, y, reduction='none')
    mse = mse.view(x.shape[0], -1).mean(dim=1)  # æ¯ä¸ªæ ·æœ¬çš„MSE
    psnr = 10 * torch.log10(1 / (mse + 1e-8))
    return psnr.mean()  # è¿”å›æ‰¹æ¬¡å‡å€¼ï¼ˆå¼ é‡ï¼‰


def SSIM(x, y):
    """è®¡ç®—SSIMï¼ˆæ‰¹æ¬¡çº§ï¼Œè¿”å›å¼ é‡ï¼‰"""
    x = x.clamp(0, 1)
    y = y.clamp(0, 1)
    C1 = 0.01 ** 2
    C2 = 0.03 ** 2

    mu_x = F.avg_pool2d(x, 3, 1, 1)
    mu_y = F.avg_pool2d(y, 3, 1, 1)

    sigma_x = F.avg_pool2d(x ** 2, 3, 1, 1) - mu_x ** 2
    sigma_y = F.avg_pool2d(y ** 2, 3, 1, 1) - mu_y ** 2
    sigma_xy = F.avg_pool2d(x * y, 3, 1, 1) - mu_x * mu_y

    ssim_map = ((2 * mu_x * mu_y + C1) * (2 * sigma_xy + C2)) / \
               ((mu_x ** 2 + mu_y ** 2 + C1) * (sigma_x + sigma_y + C2))
    return ssim_map.mean()


# -------------------- å¯¹æŠ—æ€§æ”»å‡»å‡½æ•°ï¼ˆFGSM/PGDï¼‰ --------------------
def fgsm_attack(image, epsilon, data_grad):
    """FGSMå¯¹æŠ—æ€§æ”»å‡»ï¼šç”Ÿæˆå¯¹æŠ—æ ·æœ¬"""
    sign_data_grad = data_grad.sign()  # æ¢¯åº¦ç¬¦å·
    perturbed_image = image + epsilon * sign_data_grad
    return torch.clamp(perturbed_image, 0, 1)


def pgd_attack(image, epsilon, data_grad, steps=4, alpha=0.01):
    """PGDå¯¹æŠ—æ€§æ”»å‡»ï¼šè¿­ä»£ç‰ˆFGSM"""
    perturbed_image = image.clone()
    for _ in range(steps):
        sign_data_grad = data_grad.sign()
        perturbed_image = perturbed_image + alpha * sign_data_grad
        # é™åˆ¶æ‰°åŠ¨èŒƒå›´
        perturbed_image = torch.clamp(perturbed_image, image - epsilon, image + epsilon)
        perturbed_image = torch.clamp(perturbed_image, 0, 1)
    return perturbed_image


# -------------------- æ‰©å±•æ”»å‡»å‡½æ•°ï¼ˆåŒ…å«å¯¹æŠ—æ€§æ”»å‡»ï¼‰ --------------------
def attack_image(img, attack_type, container_grad=None, epsilon=0.05):
    """
    æ‰©å±•æ”»å‡»å‡½æ•°ï¼šåŒ…å«é«˜æ–¯ã€JPEGã€å‡ ä½•ã€FGSMã€PGDæ”»å‡»
    img: è¾“å…¥å›¾åƒï¼ˆ0~1ï¼‰
    attack_type: æ”»å‡»ç±»å‹ï¼ˆgaussian/jpeg/geometry/fgsm/pgdï¼‰
    container_grad: å›¾åƒæ¢¯åº¦ï¼ˆç”¨äºå¯¹æŠ—æ€§æ”»å‡»ï¼‰
    epsilon: æ‰°åŠ¨å¼ºåº¦ï¼ˆå¯¹æŠ—æ€§æ”»å‡»ï¼‰
    """
    img = img.clamp(0, 1)
    if attack_type == "gaussian":
        noise = torch.randn_like(img) * getattr(c, 'gaussian_noise_std', 0.01)
        return (img + noise).clamp(0, 1)
    elif attack_type == "jpeg":
        img = img * 255
        img = torch.round(img / getattr(c, 'jpeg_quant_step', 10)) * getattr(c, 'jpeg_quant_step', 10)
        return (img / 255).clamp(0, 1)
    elif attack_type == "geometry":
        scale = np.random.uniform(0.9, 1.1)
        h, w = img.shape[2], img.shape[3]
        img_scaled = F.interpolate(img, scale_factor=scale, mode="bilinear", align_corners=False)
        # è£å‰ª/å¡«å……å›åŸå°ºå¯¸
        img_scaled = img_scaled[:, :, :h, :w] if img_scaled.shape[2] >= h else F.pad(img_scaled,
                                                                                     (0, 0, 0, h - img_scaled.shape[2]))
        img_scaled = img_scaled[:, :, :, :w] if img_scaled.shape[3] >= w else F.pad(img_scaled,
                                                                                    (0, w - img_scaled.shape[3], 0, 0))
        return img_scaled.clamp(0, 1)
    elif attack_type == "fgsm":
        if container_grad is None:
            return img  # æ— æ¢¯åº¦æ—¶è¿”å›åŸå›¾åƒ
        return fgsm_attack(img, epsilon, container_grad)
    elif attack_type == "pgd":
        if container_grad is None:
            return img
        # ä½¿ç”¨configä¸­çš„å‚æ•°
        return pgd_attack(img, epsilon, container_grad, steps=c.pgd_steps, alpha=c.pgd_alpha)
    return img


# ===================== ç¤ºä¾‹å›¾ç‰‡ä¿å­˜å‡½æ•°ï¼ˆä¼˜åŒ–ç‰ˆï¼‰ =====================
def save_sample_images(model, dataloader, num_samples=50, epoch=None):
    """
    ä¿å­˜ç¤ºä¾‹å›¾ç‰‡ï¼ˆä¼˜åŒ–ç‰ˆï¼‰ï¼š
    1. ä¿å­˜å•ç‹¬çš„å®¿ä¸»/å®¹å™¨/ç§˜å¯†/æå–å›¾åƒ
    2. ä¿å­˜æ‹¼æ¥çš„å¯¹æ¯”å›¾
    3. æ”¯æŒæŒ‰epochä¿å­˜
    """
    model.eval()
    count = 0
    epoch_suffix = f"_epoch_{epoch}" if epoch is not None else ""

    with torch.no_grad():
        for host_imgs, secret_imgs in tqdm(dataloader, desc="ä¿å­˜ç¤ºä¾‹å›¾ç‰‡"):
            if count >= num_samples:
                break

            host_imgs = host_imgs.to(DEVICE)
            secret_imgs = secret_imgs.to(DEVICE)

            # æ‰§è¡Œéšå†™æ“ä½œï¼ˆé€‚é…EnhancedPRISçš„è¾“å‡ºï¼‰
            if hasattr(model, 'embed'):
                container_imgs = model.embed(host_imgs, secret_imgs)
                extracted_imgs = model.extract(container_imgs)
            else:
                # å…¼å®¹åŸæ¨¡å‹çš„å‰å‘ä¼ æ’­
                container_imgs, _, _ = model(host_imgs, secret_imgs)
                extracted_imgs = model(container_imgs, secret_imgs, rev=True)

            # è½¬æ¢ä¸º0~1èŒƒå›´
            host_imgs_01 = (host_imgs + 1) / 2
            container_imgs_01 = (container_imgs + 1) / 2
            secret_imgs_01 = (secret_imgs + 1) / 2
            extracted_imgs_01 = extracted_imgs.clamp(0, 1)

            # ä¿å­˜æ‰¹æ¬¡ä¸­çš„æ¯å¼ å›¾åƒ
            for i in range(host_imgs.size(0)):
                if count >= num_samples:
                    break

                # è½¬æ¢ä¸ºPILå›¾åƒ
                def tensor_to_pil(tensor):
                    tensor = tensor.cpu().clamp(0, 1)
                    if tensor.shape[0] == 1:
                        return Image.fromarray((tensor.squeeze(0).numpy() * 255).astype(np.uint8), mode='L')
                    else:
                        return Image.fromarray((tensor.permute(1, 2, 0).numpy() * 255).astype(np.uint8), mode='RGB')

                host_img = tensor_to_pil(host_imgs_01[i])
                container_img = tensor_to_pil(container_imgs_01[i])
                secret_img = tensor_to_pil(secret_imgs_01[i])
                extracted_img = tensor_to_pil(extracted_imgs_01[i])

                # ä¿å­˜å•ç‹¬å›¾åƒ
                idx = count + 1
                host_img.save(os.path.join(c.IMAGE_PATH_host, f'host{epoch_suffix}_{idx}.png'))
                container_img.save(os.path.join(c.IMAGE_PATH_container, f'container{epoch_suffix}_{idx}.png'))
                secret_img.save(os.path.join(c.IMAGE_PATH_secret, f'secret{epoch_suffix}_{idx}.png'))
                extracted_img.save(os.path.join(c.IMAGE_PATH_extracted, f'extracted{epoch_suffix}_{idx}.png'))

                # ä¿å­˜æ‹¼æ¥å¯¹æ¯”å›¾
                fig, axes = plt.subplots(2, 2, figsize=(12, 12))
                axes[0, 0].imshow(host_img)
                axes[0, 0].set_title("Host Image", fontsize=14)
                axes[0, 0].axis('off')

                axes[0, 1].imshow(container_img)
                axes[0, 1].set_title("Container Image", fontsize=14)
                axes[0, 1].axis('off')

                axes[1, 0].imshow(secret_img)
                axes[1, 0].set_title("Original Secret", fontsize=14)
                axes[1, 0].axis('off')

                axes[1, 1].imshow(extracted_img)
                axes[1, 1].set_title("Extracted Secret", fontsize=14)
                axes[1, 1].axis('off')

                plt.tight_layout()
                plt.savefig(os.path.join(c.IMAGE_PATH_combined, f'combined{epoch_suffix}_{idx}.png'), dpi=300,
                            bbox_inches='tight')
                plt.close()

                count += 1

    print(f"\nå·²ä¿å­˜{count}å¼ ç¤ºä¾‹å›¾ç‰‡ï¼š")
    print(
        f"- å•ç‹¬å›¾åƒï¼š{c.IMAGE_PATH_host} / {c.IMAGE_PATH_container} / {c.IMAGE_PATH_secret} / {c.IMAGE_PATH_extracted}")
    print(f"- å¯¹æ¯”å›¾åƒï¼š{c.IMAGE_PATH_combined}")
    model.train()


# ===================== æ¨¡å‹æ‰©å±•ç±»ï¼ˆä¼˜åŒ–ç‰ˆï¼‰ =====================
# -------------------- 1. DCGANç”Ÿæˆå™¨ï¼ˆèåˆå¤šåŸŸç‰¹å¾ï¼‰ --------------------
class DCGANGenerator(nn.Module):
    """DCGANç”Ÿæˆå™¨ï¼šèåˆå¤šåŸŸç‰¹å¾ï¼Œç”Ÿæˆå…¨å±€é²æ£’+å±€éƒ¨å¯é€†çš„å®¹å™¨å›¾åƒ"""

    def __init__(self, in_channels=64, out_channels=3):
        super().__init__()
        self.model = nn.Sequential(
            # è¾“å…¥ï¼šèåˆåçš„å¤šåŸŸç‰¹å¾ (batch, 64, h, w)
            nn.Conv2d(in_channels, 128, 3, padding=1),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2, inplace=True),
            # åå·ç§¯ä¸Šé‡‡æ ·ï¼ˆé€‚é…å›¾åƒåˆ†è¾¨ç‡ï¼‰
            nn.ConvTranspose2d(128, 64, 4, 2, 1),  # (b,64,2h,2w)
            nn.BatchNorm2d(64),
            nn.LeakyReLU(0.2, inplace=True),
            # è¾“å‡º3é€šé“å®¹å™¨å›¾åƒï¼ˆ-1~1ï¼‰
            nn.Conv2d(64, out_channels, 3, padding=1),
            nn.Tanh()
        )

    def forward(self, x):
        return self.model(x)


# -------------------- 2. ç”Ÿæˆå¼è¯¯å·®é¢„åˆ¤å™¨ï¼ˆä¼˜åŒ–ç‰ˆï¼šæ”¯æŒè¯¯å·®ä¿®æ­£ï¼‰ --------------------
class GenerativeErrorPredictor(nn.Module):
    """ç”Ÿæˆå¼è¯¯å·®é¢„åˆ¤ï¼šé¢„åˆ¤åƒç´ /rounding/é‡åŒ–è¯¯å·®ï¼Œè”åŠ¨DCGANç”Ÿæˆå™¨è¿›è¡Œä¿®æ­£"""

    def __init__(self, in_channels=3):
        super().__init__()
        # åƒç´ è¯¯å·®é¢„åˆ¤
        self.pixel_err = nn.Sequential(
            nn.Conv2d(in_channels, 32, 3, padding=1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(32, in_channels, 3, padding=1)
        )
        # Roundingè¯¯å·®é¢„åˆ¤ï¼ˆæ¨¡æ‹Ÿå›¾åƒä¿å­˜æ—¶çš„å››èˆäº”å…¥ï¼‰
        self.round_err = nn.Sequential(
            nn.Conv2d(in_channels, 32, 3, padding=1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(32, in_channels, 3, padding=1)
        )
        # é‡åŒ–è¯¯å·®é¢„åˆ¤ï¼ˆæ¨¡æ‹Ÿ8bité‡åŒ–ï¼‰
        self.quant_err = nn.Sequential(
            nn.Conv2d(in_channels, 32, 3, padding=1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(32, in_channels, 3, padding=1)
        )

    def forward(self, x, simulate_round=True, simulate_quant=True):
        """
        x: å®¹å™¨å›¾åƒï¼ˆ-1~1ï¼‰
        return: æ€»è¯¯å·®ï¼ˆ-1~1ï¼‰+ å„åˆ†é¡¹è¯¯å·®
        """
        # åƒç´ è¯¯å·®
        pixel_err = self.pixel_err(x)
        total_err = pixel_err

        # Roundingè¯¯å·®ï¼šæ¨¡æ‹Ÿ0-255æ•´æ•°åŒ–çš„è¯¯å·®
        if simulate_round:
            x_255 = (x + 1) * 127.5  # è½¬æ¢ä¸º0-255
            x_round = torch.round(x_255)
            x_round_norm = (x_round / 127.5) - 1  # è½¬å›-1~1
            round_err = self.round_err(x - x_round_norm)
            total_err += round_err

        # é‡åŒ–è¯¯å·®ï¼šæ¨¡æ‹Ÿ8bité‡åŒ–çš„è¯¯å·®
        if simulate_quant:
            x_quant = torch.clamp(torch.floor((x + 1) * 127.5) / 127.5 - 1, -1, 1)
            quant_err = self.quant_err(x - x_quant)
            total_err += quant_err

        return total_err, pixel_err, round_err, quant_err

    def correct_image(self, x, error, correction_weight=0.1):
        """ä½¿ç”¨é¢„æµ‹è¯¯å·®ä¿®æ­£å›¾åƒ"""
        corrected_x = x - correction_weight * error
        return torch.clamp(corrected_x, -1, 1)


# -------------------- 3. åˆ¤åˆ«å™¨ï¼ˆä¼˜åŒ–ç‰ˆï¼šæ”¯æŒä¸­é—´ç‰¹å¾æå–ï¼‰ --------------------
class Discriminator(nn.Module):
    """DCGANåˆ¤åˆ«å™¨ï¼šæ”¯æŒä¸­é—´ç‰¹å¾æå–ï¼Œç”¨äºå¤šåŸŸé—­ç¯èåˆ"""

    def __init__(self, in_channels=3):
        super().__init__()
        # æ‹†åˆ†æ¨¡å—ï¼Œä¾¿äºè·å–ä¸­é—´ç‰¹å¾
        self.layer1 = nn.Sequential(
            nn.Conv2d(in_channels, 64, 4, 2, 1),
            nn.LeakyReLU(0.2, inplace=True)
        )
        self.layer2 = nn.Sequential(
            nn.Conv2d(64, 128, 4, 2, 1),
            nn.BatchNorm2d(128),
            nn.LeakyReLU(0.2, inplace=True)
        )
        self.layer3 = nn.Sequential(
            nn.Conv2d(128, 256, 4, 2, 1),
            nn.BatchNorm2d(256),
            nn.LeakyReLU(0.2, inplace=True)
        )
        self.layer4 = nn.Sequential(
            nn.Conv2d(256, 1, 4, 1, 0),
            nn.Sigmoid()
        )

    def forward(self, x):
        """å‰å‘ä¼ æ’­ï¼šè¾“å‡ºåˆ¤åˆ«è¯„åˆ†"""
        x1 = self.layer1(x)
        x2 = self.layer2(x1)
        x3 = self.layer3(x2)
        x4 = self.layer4(x3)
        return x4

    def get_intermediate_features(self, x):
        """è·å–ä¸­é—´å±‚ç‰¹å¾ï¼ˆlayer3è¾“å‡ºï¼‰ï¼Œç”¨äºç‰¹å¾åŒ¹é…æŸå¤±"""
        x1 = self.layer1(x)
        x2 = self.layer2(x1)
        x3 = self.layer3(x2)
        return x3


# -------------------- 4. åˆ¤åˆ«å™¨è¾…åŠ©ä¿®å¤å¤´ï¼ˆä¼˜åŒ–ç‰ˆï¼šåˆ©ç”¨ä¸­é—´ç‰¹å¾ï¼‰ --------------------
class DiscriminatorRefineHead(nn.Module):
    """åˆ©ç”¨DCGANåˆ¤åˆ«å™¨çš„ä¸­é—´ç‰¹å¾ç²¾ç»†åŒ–ä¿®å¤æå–çš„ç§˜å¯†å›¾åƒ"""

    def __init__(self, in_channels=3, disc=None):
        super().__init__()
        self.disc = disc  # ä¼ å…¥DCGANåˆ¤åˆ«å™¨
        self.refine = nn.Sequential(
            nn.Conv2d(in_channels, 32, 3, padding=1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(32, 16, 3, padding=1),
            nn.LeakyReLU(0.2),
            nn.Conv2d(16, in_channels, 3, padding=1),
            nn.Sigmoid()
        )
        # ç‰¹å¾èåˆå±‚ï¼ˆåˆ¤åˆ«å™¨ä¸­é—´ç‰¹å¾ + æå–å›¾åƒç‰¹å¾ï¼‰
        self.feat_fusion = nn.Sequential(
            nn.Conv2d(in_channels + 256, 64, 1, 1, 0),
            nn.LeakyReLU(0.2),
            nn.Conv2d(64, in_channels, 1, 1, 0)
        )

    def forward(self, x):
        """
        x: æå–çš„ç§˜å¯†å›¾åƒï¼ˆ0~1ï¼‰
        return: ä¿®å¤åçš„ç§˜å¯†å›¾åƒ
        """
        # åˆæ­¥ä¿®å¤
        x_refine = self.refine(x)

        # è·å–åˆ¤åˆ«å™¨ä¸­é—´ç‰¹å¾ï¼ˆä¸Šé‡‡æ ·åˆ°åŸå°ºå¯¸ï¼‰
        disc_feat = self.disc.get_intermediate_features(x_refine)
        disc_feat = F.interpolate(disc_feat, size=x.shape[2:], mode='bilinear', align_corners=False)

        # ç‰¹å¾èåˆ
        x_concat = torch.cat([x_refine, disc_feat], dim=1)
        x_fused = self.feat_fusion(x_concat)

        # è‡ªé€‚åº”ä¿®å¤å¼ºåº¦
        disc_score = self.disc(x_refine).mean(dim=[1, 2, 3]).view(-1, 1, 1, 1)
        refine_strength = torch.clamp(1 - disc_score, 0.1, 1.0)

        # æœ€ç»ˆä¿®å¤
        x_final = x_refine * refine_strength + x_fused * (1 - refine_strength)
        return x_final.clamp(0, 1)


# -------------------- 5. åŠ¨æ€æƒé‡å¹³è¡¡å™¨ï¼ˆä¼˜åŒ–ç‰ˆï¼šä¸‰ç›®æ ‡åŠ¨æ€å¹³è¡¡+æŸå¤±åé¦ˆï¼‰ --------------------
class DynamicWeightBalancer:
    """
    ä¸‰ç›®æ ‡åŠ¨æ€å¹³è¡¡å™¨ï¼šå®¹é‡-é²æ£’æ€§-ä¸å¯æ„ŸçŸ¥æ€§
    ä¼˜åŒ–ç‚¹ï¼šç»“åˆçº¹ç†å¤æ‚åº¦ã€æ”»å‡»ç±»å‹ã€å½“å‰æŸå¤±å€¼è¿›è¡ŒåŠ¨æ€è°ƒæ•´
    """

    def __init__(self, base_weights={'cap': 1.0, 'rob': 1.0, 'imp': 1.0}):
        self.base_weights = base_weights
        self.loss_history = {'cap': [], 'rob': [], 'imp': []}  # æŸå¤±å†å²

    def adjust(self, texture_complexity, attack_type, current_losses=None):
        """
        texture_complexity: PZMsè®¡ç®—çš„çº¹ç†å¤æ‚åº¦ï¼ˆbatchç»´åº¦å¼ é‡ï¼‰
        attack_type: æ”»å‡»ç±»å‹ï¼ˆgaussian/jpeg/geometry/fgsm/pgdï¼‰
        current_losses: å½“å‰æŸå¤±å€¼ï¼ˆdict: cap/rob/impï¼‰
        return: åŠ¨æ€æƒé‡ï¼ˆcap_w, rob_w, imp_wï¼‰â†’ æ ‡é‡å¼ é‡
        """
        # 1. çº¹ç†å¤æ‚åº¦å½’ä¸€åŒ–ï¼ˆ0~1ï¼‰
        tex_min = torch.min(texture_complexity)
        tex_max = torch.max(texture_complexity)
        tex_norm = (texture_complexity - tex_min) / (tex_max - tex_min + 1e-8)
        tex_norm = torch.mean(tex_norm)  # æ‰¹æ¬¡å‡å€¼

        # 2. åŸºç¡€æƒé‡ï¼šçº¹ç†å¤æ‚åº¦å½±å“
        cap_w = self.base_weights['cap'] * (1 + tex_norm)
        imp_w = self.base_weights['imp'] * (1 - tex_norm)
        rob_w = torch.tensor(self.base_weights['rob'], device=texture_complexity.device)

        # 3. æ”»å‡»ç±»å‹è°ƒæ•´é²æ£’æ€§æƒé‡
        if attack_type in ['geometry', 'fgsm', 'pgd']:
            rob_w *= 2.0
        elif attack_type in ['jpeg']:
            rob_w *= 1.5
        else:
            rob_w *= 1.0

        # 4. å½“å‰æŸå¤±å€¼åé¦ˆè°ƒæ•´ï¼ˆæ ¸å¿ƒï¼šæŸå¤±è¶Šå¤§ï¼Œæƒé‡è¶Šé«˜ï¼‰
        if current_losses is not None:
            # æ›´æ–°æŸå¤±å†å²
            for key in ['cap', 'rob', 'imp']:
                self.loss_history[key].append(current_losses[key])
                if len(self.loss_history[key]) > 10:  # ä¿ç•™æœ€è¿‘10è½®
                    self.loss_history[key].pop(0)

            # æŸå¤±å½’ä¸€åŒ–ï¼ˆç›¸å¯¹äºå†å²æœ€å¤§å€¼ï¼‰
            cap_loss_norm = current_losses['cap'] / (max(self.loss_history['cap']) + 1e-8)
            rob_loss_norm = current_losses['rob'] / (max(self.loss_history['rob']) + 1e-8)
            imp_loss_norm = current_losses['imp'] / (max(self.loss_history['imp']) + 1e-8)

            # è°ƒæ•´æƒé‡
            cap_w *= (1 + cap_loss_norm)
            rob_w *= (1 + rob_loss_norm)
            imp_w *= (1 + imp_loss_norm)

        # 5. æƒé‡å½’ä¸€åŒ–
        total = cap_w + rob_w + imp_w + 1e-8
        return cap_w / total, rob_w / total, imp_w / total


# ===================== æ•°æ®é›†åŠ è½½ï¼ˆä¼˜åŒ–ç‰ˆï¼šæ·»åŠ æ•°æ®å¢å¼ºï¼‰ =====================
class WatermarkDataset(Dataset):
    def __init__(self, split="train", max_samples=None):
        self.split = split
        self.img_size = (c.channels_in, c.cropsize, c.cropsize) if split == "train" else (
        c.channels_in, c.cropsize_val, c.cropsize_val)

        # æ•°æ®å¢å¼ºï¼ˆä»…è®­ç»ƒé›†ï¼‰
        if split == "train":
            self.transform = transforms.Compose([
                transforms.Resize((self.img_size[1] + 10, self.img_size[2] + 10), Image.BICUBIC),
                transforms.RandomCrop((self.img_size[1], self.img_size[2])),
                transforms.RandomHorizontalFlip(),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
            ])
        else:
            self.transform = transforms.Compose([
                transforms.Resize((self.img_size[1], self.img_size[2]), Image.BICUBIC),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
            ])

        # ä»configè·å–è·¯å¾„
        if split == "train":
            self.img_paths = sorted(glob.glob(os.path.join(c.TRAIN_PATH, f"*.{c.format_train}")))
        else:
            self.img_paths = sorted(glob.glob(os.path.join(c.VAL_PATH, f"*.{c.format_val}")))

        # æ£€æŸ¥æ•°æ®é›†æ˜¯å¦ä¸ºç©º
        if len(self.img_paths) == 0:
            raise ValueError(f"æ•°æ®é›†è·¯å¾„ä¸‹æœªæ‰¾åˆ°å›¾åƒæ–‡ä»¶: {c.TRAIN_PATH if split == 'train' else c.VAL_PATH}")

        if max_samples is not None:
            self.img_paths = self.img_paths[:max_samples]

        # æ ¸å¿ƒï¼šæ‹†åˆ†hostå’Œsecretï¼ˆéšæœºé…å¯¹ï¼‰
        self.host_paths = self.img_paths
        self.secret_paths = self.img_paths.copy()
        random.shuffle(self.secret_paths)

    def __len__(self):
        return len(self.host_paths)

    def __getitem__(self, idx):
        host_path = self.host_paths[idx]
        host_img = Image.open(host_path).convert("RGB")
        host = self.transform(host_img).clamp(-1, 1)

        secret_path = self.secret_paths[idx]
        secret_img = Image.open(secret_path).convert("RGB")
        secret = self.transform(secret_img).clamp(-1, 1)

        return host, secret


# ===================== è®­ç»ƒå‡½æ•°ï¼ˆä¼˜åŒ–ç‰ˆï¼‰ =====================
def train_epoch(net, disc, error_predictor, loader, optim_gen, optim_disc, epoch, writer, mode="train",
                weight_balancer=None):
    """
    å•è½®è®­ç»ƒ/éªŒè¯å‡½æ•°ï¼ˆä¼˜åŒ–ç‰ˆï¼‰ï¼š
    1. æ·»åŠ ç‰¹å¾åŒ¹é…æŸå¤±ï¼ˆå¤šåŸŸé—­ç¯èåˆï¼‰
    2. ä¼˜åŒ–æ¢¯åº¦è®¡ç®—
    3. å®Œå–„æŸå¤±è®°å½•
    4. æ‰¹æ¬¡çº§è¿›åº¦æ¡
    """
    net.train() if mode == "train" else net.eval()
    disc.train() if mode == "train" else disc.eval()
    error_predictor.train() if mode == "train" else error_predictor.eval()

    total_loss = 0
    psnr_list = []
    ssim_list = []
    epsilon = c.epsilon  # ä»configè¯»å–æ”»å‡»å¼ºåº¦

    pbar = tqdm(loader, desc=f"{mode} Epoch {epoch + 1}", leave=False)
    for batch_idx, (host, secret) in enumerate(pbar):
        host, secret = host.to(DEVICE), secret.to(DEVICE)
        batch_size = host.shape[0]
        # æ‰©å±•æ”»å‡»ç±»å‹ï¼šä»configè¯»å–æ”¯æŒçš„æ”»å‡»
        attack_type = np.random.choice(c.supported_attacks)

        with torch.set_grad_enabled(mode == "train"):
            # -------------------- æ­£å‘åµŒå…¥ï¼šç”Ÿæˆå®¹å™¨å›¾åƒ --------------------
            if hasattr(net, 'embed'):
                container = net.embed(host, secret)
            else:
                container, pred_error, pzms_feat = net(host, secret)

            # ç”Ÿæˆå¼è¯¯å·®é¢„åˆ¤ + å›¾åƒä¿®æ­£ï¼ˆæ ¸å¿ƒåˆ›æ–°ç‚¹ï¼šè¯¯å·®é¢„åˆ¤ç”¨äºä¿®æ­£ï¼‰
            pred_error_total, _, _, _ = error_predictor(container)
            container_corrected = error_predictor.correct_image(container, pred_error_total, c.error_correction_weight)
            container_corrected = torch.clamp(container_corrected, -1, 1)

            # è½¬æ¢ä¸º0~1èŒƒå›´ï¼ˆç”¨äºæ”»å‡»å’Œè¯„ä¼°ï¼‰
            container_01 = (container_corrected + 1) / 2
            host_01 = (host + 1) / 2
            container_01.requires_grad = True if mode == "train" else False

            # -------------------- ç”Ÿæˆå¯¹æŠ—æ€§æ”»å‡»æ‰€éœ€çš„æ¢¯åº¦ --------------------
            container_grad = None
            if mode == "train" and attack_type in ["fgsm", "pgd"]:
                # è®¡ç®—åˆ¤åˆ«å™¨å¯¹å®¹å™¨å›¾åƒçš„é¢„æµ‹æ¢¯åº¦ï¼ˆæ›´é«˜æ•ˆï¼‰
                pred = disc(container_01)
                loss_temp = F.binary_cross_entropy(pred, torch.ones_like(pred))
                loss_temp.backward(retain_graph=True)
                container_grad = container_01.grad.data
                container_01.grad.zero_()

            # -------------------- æ–½åŠ æ”»å‡» --------------------
            attacked_container = attack_image(container_01, attack_type, container_grad, epsilon)
            actual_error = container_01 - attacked_container.detach()

            # -------------------- é€†å‘æå–ï¼šç§˜å¯†å›¾åƒ --------------------
            if hasattr(net, 'extract'):
                extracted = net.extract(container_corrected)
            else:
                extracted = net(attacked_container, secret, rev=True)
            extracted = extracted.clamp(0, 1)

            # -------------------- åŠ¨æ€æƒé‡è®¡ç®— --------------------
            # å‡è®¾netæœ‰pzms_extractorå±æ€§ï¼ˆé€‚é…åŸæ¨¡å‹ï¼‰
            if hasattr(net, 'pzms_extractor'):
                pzms_complexity = net.pzms_extractor.get_texture_complexity(host)
            else:
                pzms_complexity = torch.rand(batch_size, device=DEVICE)  # æ¨¡æ‹Ÿçº¹ç†å¤æ‚åº¦

            # è®¡ç®—åŸºç¡€æŸå¤±ï¼ˆç”¨äºåŠ¨æ€æƒé‡ï¼‰
            cap_loss = F.mse_loss(extracted, (secret + 1) / 2)
            rob_loss = F.mse_loss(container_01, attacked_container)
            imp_loss = 1 - SSIM(container_01, host_01)

            # æ”¶é›†å½“å‰æŸå¤±å€¼
            current_losses = {
                'cap': cap_loss.item(),
                'rob': rob_loss.item(),
                'imp': imp_loss.item()
            }

            # åŠ¨æ€è°ƒæ•´æƒé‡ï¼ˆä¸‰ç›®æ ‡åŠ¨æ€å¹³è¡¡ï¼‰
            cap_weight, rob_weight, imp_weight = weight_balancer.adjust(pzms_complexity, attack_type, current_losses)

            # -------------------- æŸå¤±è®¡ç®— --------------------
            # ä¸‰ç›®æ ‡æŸå¤±
            content_loss = cap_weight * cap_loss + rob_weight * rob_loss + imp_weight * imp_loss

            # è¯¯å·®é¢„åˆ¤æŸå¤±ï¼ˆç”Ÿæˆå¼è¯¯å·®è¡¥å¿ï¼‰
            pred_error_01 = (pred_error_total + 1) / 2
            error_pred_loss = F.mse_loss(pred_error_01, actual_error)

            # å¯¹æŠ—æ€§æŸå¤±ï¼ˆæ³›åŒ–å¢å¼ºï¼‰
            adv_loss = torch.tensor(0.0, device=DEVICE)
            if attack_type in ["fgsm", "pgd"]:
                adv_loss = F.mse_loss(extracted, (secret + 1) / 2) * c.adv_loss_weight

            # ç‰¹å¾åŒ¹é…æŸå¤±ï¼ˆå¤šåŸŸé—­ç¯èåˆï¼šæ ¸å¿ƒåˆ›æ–°ç‚¹ï¼‰
            feat_match_loss = torch.tensor(0.0, device=DEVICE)
            if mode == "train":
                real_feat = disc.get_intermediate_features(host_01)
                fake_feat = disc.get_intermediate_features(container_01)
                feat_match_loss = F.mse_loss(fake_feat, real_feat.detach()) * c.feat_match_weight

            current_loss = 0
            if mode == "train":
                # -------------------- åˆ¤åˆ«å™¨è®­ç»ƒ --------------------
                optim_disc.zero_grad()
                real_pred = disc(host_01).view(-1)
                real_loss = F.binary_cross_entropy(real_pred, torch.ones_like(real_pred) * 0.9)  # æ ‡ç­¾å¹³æ»‘
                fake_pred = disc(container_01.detach()).view(-1)
                fake_loss = F.binary_cross_entropy(fake_pred, torch.zeros_like(fake_pred))
                disc_loss = (real_loss + fake_loss) / 2
                disc_loss.backward(retain_graph=True)
                torch.nn.utils.clip_grad_norm_(disc.parameters(), max_norm=1.0)  # æ¢¯åº¦è£å‰ª
                optim_disc.step()

                # -------------------- ç”Ÿæˆå™¨è®­ç»ƒ --------------------
                optim_gen.zero_grad()
                # GANå¯¹æŠ—æŸå¤±
                gan_pred = disc(container_01).view(-1)
                gan_loss = F.binary_cross_entropy(gan_pred, torch.ones_like(gan_pred))
                # æ€»æŸå¤±ï¼šèåˆæ‰€æœ‰æŸå¤±é¡¹
                total_gen_loss = (
                        content_loss +
                        c.gan_weight * gan_loss +
                        c.error_pred_weight * error_pred_loss +
                        adv_loss +
                        feat_match_loss
                )
                total_gen_loss.backward()
                torch.nn.utils.clip_grad_norm_(net.parameters(), max_norm=1.0)  # æ¢¯åº¦è£å‰ª
                optim_gen.step()
                current_loss = total_gen_loss.item()

                # æ›´æ–°è¿›åº¦æ¡
                pbar.set_postfix({
                    'Loss': f'{current_loss:.4f}',
                    'CapW': f'{cap_weight.item():.2f}',
                    'RobW': f'{rob_weight.item():.2f}',
                    'ImpW': f'{imp_weight.item():.2f}'
                })
            else:
                current_loss = (content_loss + error_pred_loss + adv_loss).item()

            # -------------------- è¯„ä¼°æŒ‡æ ‡æ”¶é›† --------------------
            total_loss += current_loss
            psnr_list.append(PSNR(extracted, (secret + 1) / 2).item())
            ssim_list.append(SSIM(extracted, (secret + 1) / 2).item())

    # -------------------- æ‰¹æ¬¡å¹³å‡è®¡ç®— --------------------
    avg_loss = total_loss / len(loader)
    avg_psnr = np.mean(psnr_list)
    avg_ssim = np.mean(ssim_list)
    print(f"\n{mode} Epoch {epoch + 1}: Loss={avg_loss:.4f}, PSNR={avg_psnr:.2f} dB, SSIM={avg_ssim:.4f}")

    # -------------------- å¼ é‡æ¿æ—¥å¿— --------------------
    if writer is not None:
        writer.add_scalar(f"{mode}/Loss", avg_loss, epoch)
        writer.add_scalar(f"{mode}/PSNR", avg_psnr, epoch)
        writer.add_scalar(f"{mode}/SSIM", avg_ssim, epoch)
        writer.add_scalar(f"{mode}/Cap_Weight", cap_weight.item(), epoch)
        writer.add_scalar(f"{mode}/Rob_Weight", rob_weight.item(), epoch)
        writer.add_scalar(f"{mode}/Imp_Weight", imp_weight.item(), epoch)
        writer.add_scalar(f"{mode}/Feat_Match_Loss", feat_match_loss.item(), epoch)
        writer.add_scalar(f"{mode}/Error_Pred_Loss", error_pred_loss.item(), epoch)

    return avg_loss, avg_psnr, avg_ssim


# ===================== åŠ è½½/ä¿å­˜æœ€ä½³æ¨¡å‹ =====================
def load_best_model(net, disc, error_predictor, optim_gen, optim_disc, checkpoint_path):
    """åŠ è½½æœ€ä½³æ¨¡å‹ï¼ˆæ”¯æŒæ–­ç‚¹ç»­è®­ï¼‰"""
    start_epoch = 0
    best_psnr = 0.0
    if os.path.exists(checkpoint_path):
        checkpoint = torch.load(checkpoint_path, map_location=DEVICE)
        net.load_state_dict(checkpoint['net_state_dict'])
        disc.load_state_dict(checkpoint['disc_state_dict'])
        error_predictor.load_state_dict(checkpoint['error_predictor_state_dict'])
        optim_gen.load_state_dict(checkpoint['optim_gen_state_dict'])
        optim_disc.load_state_dict(checkpoint['optim_disc_state_dict'])
        start_epoch = checkpoint.get('epoch', 0)
        best_psnr = checkpoint.get('best_psnr', 0.0)
        print(f"âœ… åŠ è½½æœ€ä½³æ¨¡å‹æˆåŠŸï¼š{checkpoint_path}")
        print(f"  - èµ·å§‹Epoch: {start_epoch + 1}, å†å²æœ€ä½³PSNR: {best_psnr:.2f} dB")
    else:
        print(f"âŒ æœªæ‰¾åˆ°æœ€ä½³æ¨¡å‹ï¼š{checkpoint_path}ï¼Œå°†ä»å¤´å¼€å§‹è®­ç»ƒ")
    return start_epoch, best_psnr


def save_best_model(net, disc, error_predictor, optim_gen, optim_disc, epoch, psnr, checkpoint_path):
    """ä¿å­˜æœ€ä½³æ¨¡å‹"""
    torch.save({
        'epoch': epoch,
        'net_state_dict': net.state_dict(),
        'disc_state_dict': disc.state_dict(),
        'error_predictor_state_dict': error_predictor.state_dict(),
        'optim_gen_state_dict': optim_gen.state_dict(),
        'optim_disc_state_dict': optim_disc.state_dict(),
        'best_psnr': psnr
    }, checkpoint_path)
    print(f"âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ˆPSNR: {psnr:.2f} dBï¼‰ï¼š{checkpoint_path}")


# ===================== ä¸»è®­ç»ƒå‡½æ•°ï¼ˆä¼˜åŒ–ç‰ˆï¼‰ =====================
def train():
    # -------------------- åˆå§‹åŒ–ç»„ä»¶ --------------------
    # åŠ¨æ€æƒé‡å¹³è¡¡å™¨
    base_weights = {
        'cap': getattr(c, 'base_capacity_weight', 1.0),
        'rob': getattr(c, 'base_robustness_weight', 1.0),
        'imp': getattr(c, 'base_imperceptibility_weight', 1.0)
    }
    weight_balancer = DynamicWeightBalancer(base_weights=base_weights)

    # æ¨¡å‹åˆå§‹åŒ–ï¼ˆé€‚é…åŸmodel.pyçš„EnhancedPRISï¼‰
    try:
        from model import EnhancedPRIS
        disc = Discriminator(in_channels=c.channels_in).to(DEVICE)
        net = EnhancedPRIS(
            in_channels=c.channels_in,
            target_channels=c.target_channels,
            disc=disc
        ).to(DEVICE)
        # ç”Ÿæˆå¼è¯¯å·®é¢„åˆ¤å™¨
        error_predictor = GenerativeErrorPredictor(in_channels=c.channels_in).to(DEVICE)
    except ImportError as e:
        print(f"âš ï¸  æœªæ‰¾åˆ°model.pyï¼Œä½¿ç”¨å ä½æ¨¡å‹ï¼š{e}")

        # å ä½æ¨¡å‹ï¼ˆä»…ç”¨äºæµ‹è¯•ï¼‰
        class DummyModel(nn.Module):
            def __init__(self):
                super().__init__()
                self.embed = lambda h, s: h
                self.extract = lambda c: torch.rand_like(c)

        net = DummyModel().to(DEVICE)
        disc = Discriminator(in_channels=c.channels_in).to(DEVICE)
        error_predictor = GenerativeErrorPredictor(in_channels=c.channels_in).to(DEVICE)

    # ä¼˜åŒ–å™¨
    optim_gen = optim.Adam(
        list(net.parameters()) + list(error_predictor.parameters()),
        lr=c.lr_gen, betas=c.betas, weight_decay=1e-5  # æ·»åŠ æƒé‡è¡°å‡
    )
    optim_disc = optim.Adam(
        disc.parameters(),
        lr=c.lr_disc, betas=c.betas, weight_decay=1e-5
    )

    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler_gen = optim.lr_scheduler.StepLR(optim_gen, step_size=c.lr_step_size, gamma=c.lr_gamma)
    scheduler_disc = optim.lr_scheduler.StepLR(optim_disc, step_size=c.lr_step_size, gamma=c.lr_gamma)

    # æ•°æ®é›†
    train_dataset = WatermarkDataset(split="train", max_samples=c.max_train_samples)
    val_dataset = WatermarkDataset(split="val", max_samples=c.max_val_samples)
    train_loader = DataLoader(train_dataset, batch_size=c.batch_size, shuffle=True, num_workers=0, pin_memory=True)
    val_loader = DataLoader(val_dataset, batch_size=c.batchsize_val, shuffle=False, num_workers=0, pin_memory=True)

    # æ—¥å¿—
    writer = SummaryWriter(log_dir=c.LOG_PATH)

    # åŠ è½½æœ€ä½³æ¨¡å‹
    best_model_path = os.path.join(c.CHECKPOINT_PATH, "best_model.pt")
    start_epoch, best_psnr = load_best_model(net, disc, error_predictor, optim_gen, optim_disc, best_model_path)

    # æ—©åœå‚æ•°
    early_stop_patience = c.early_stop_patience
    no_improve_epochs = 0

    # -------------------- è®­ç»ƒå¾ªç¯ --------------------
    print(f"\nå¼€å§‹è®­ç»ƒï¼ˆæ€»Epoch: {c.epochs}ï¼Œèµ·å§‹Epoch: {start_epoch + 1}ï¼‰")
    for epoch in range(start_epoch, c.epochs):
        # è®­ç»ƒè½®
        train_loss, train_psnr, train_ssim = train_epoch(
            net, disc, error_predictor, train_loader, optim_gen, optim_disc,
            epoch, writer, mode="train", weight_balancer=weight_balancer
        )

        # éªŒè¯è½®
        if (epoch + 1) % c.val_freq == 0:
            with torch.no_grad():
                val_loss, val_psnr, val_ssim = train_epoch(
                    net, disc, error_predictor, val_loader, optim_gen, optim_disc,
                    epoch, writer, mode="val", weight_balancer=weight_balancer
                )

            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_psnr > best_psnr:
                best_psnr = val_psnr
                save_best_model(net, disc, error_predictor, optim_gen, optim_disc, epoch, val_psnr, best_model_path)
                no_improve_epochs = 0
                # ä¿å­˜ç¤ºä¾‹å›¾ç‰‡ï¼ˆæœ€ä½³æ¨¡å‹ï¼‰
                save_sample_images(net, val_loader, num_samples=c.num_sample_images, epoch=epoch + 1)
            else:
                no_improve_epochs += 1
                print(f"âš ï¸  éªŒè¯PSNRè¿ç»­{no_improve_epochs}è½®æœªæå‡ï¼ˆè€å¿ƒï¼š{early_stop_patience}ï¼‰")

                # æ—©åœæœºåˆ¶
                if no_improve_epochs >= early_stop_patience:
                    print(f"ğŸ›‘ æ—©åœè§¦å‘ï¼Œåœæ­¢è®­ç»ƒï¼ˆEpoch: {epoch + 1}ï¼‰")
                    break

        # ä¿å­˜å®šæœŸæ£€æŸ¥ç‚¹
        if (epoch + 1) % c.save_freq == 0:
            checkpoint_path = os.path.join(c.CHECKPOINT_PATH, f"checkpoint_{epoch + 1}.pt")
            torch.save({
                'epoch': epoch,
                'net_state_dict': net.state_dict(),
                'disc_state_dict': disc.state_dict(),
                'error_predictor_state_dict': error_predictor.state_dict(),
                'optim_gen_state_dict': optim_gen.state_dict(),
                'optim_disc_state_dict': optim_disc.state_dict(),
                'best_psnr': best_psnr
            }, checkpoint_path)
            print(f"ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹ï¼š{checkpoint_path}")

        # æ›´æ–°å­¦ä¹ ç‡
        scheduler_gen.step()
        scheduler_disc.step()

    # è®­ç»ƒå®Œæˆï¼šä¿å­˜æœ€ç»ˆç¤ºä¾‹å›¾ç‰‡
    print("\nğŸ‰ è®­ç»ƒå®Œæˆï¼Œä¿å­˜æœ€ç»ˆç¤ºä¾‹å›¾ç‰‡...")
    save_sample_images(net, val_loader, num_samples=c.num_sample_images)

    writer.close()
    print(f"\nè®­ç»ƒç»“æœï¼šæœ€ä½³PSNR = {best_psnr:.2f} dB")


if __name__ == "__main__":
    train()
