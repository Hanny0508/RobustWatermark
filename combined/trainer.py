import os
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torch.utils.tensorboard import SummaryWriter
import numpy as np
from tqdm import tqdm
import matplotlib.pyplot as plt
from PIL import Image
import torchvision.utils as vutils

# å¯¼å…¥è‡ªå®šä¹‰æ¨¡å—
import config as c
from data import StegoDataset
from Main import (
    PSNR, SSIM, attack_image, DCGANGenerator,
    GenerativeErrorPredictor, DiscriminatorRefineHead,
    DynamicWeightBalancer, Discriminator  # ä»Mainå¯¼å…¥Discriminatorï¼Œä¸å†è‡ªå®šä¹‰
)
from model import (
    EnhancedPRIS, PZMsFeatureExtractor,
    ReversibleBlock, FeatureFusionModule
)

class Trainer:
    def __init__(self):
        # è®¾å¤‡é…ç½®
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"ä½¿ç”¨è®¾å¤‡: {self.device}")

        # æ¨¡å‹åˆå§‹åŒ–
        self.gen = EnhancedPRIS().to(self.device)  # éšå†™ç”Ÿæˆå™¨
        self.disc = Discriminator(in_channels=3).to(self.device)  # ä½¿ç”¨Mainçš„Discriminator
        self.error_predictor = GenerativeErrorPredictor(in_channels=3).to(self.device)  # ä¼ å…¥in_channelsåŒ¹é…
        self.refine_head = DiscriminatorRefineHead(disc=self.disc).to(self.device)  # ä¿®å¤å¤´
        self.pzms_extractor = PZMsFeatureExtractor(max_order=c.pzms_max_order).to(self.device)  # PZMsæå–å™¨
        # åŠ¨æ€æƒé‡å¹³è¡¡å™¨ï¼ˆæ”¯æŒä¼ å…¥å½“å‰æŸå¤±å€¼ï¼‰
        self.weight_balancer = DynamicWeightBalancer(
            base_weights={
                'cap': c.base_capacity_weight,
                'rob': c.base_robustness_weight,
                'imp': c.base_imperceptibility_weight
            }
        )
        self.training = True  # æ§åˆ¶è¯¯å·®é¢„æµ‹å™¨çš„ä½¿ç”¨

        # ä¼˜åŒ–å™¨
        self.opt_gen = optim.Adam(self.gen.parameters(), lr=c.lr_gen, betas=c.betas)
        self.opt_disc = optim.Adam(self.disc.parameters(), lr=c.lr_disc, betas=c.betas)

        # å­¦ä¹ ç‡è°ƒåº¦å™¨ï¼ˆè§£å†³å­¦ä¹ ç‡å›ºå®šé—®é¢˜ï¼‰
        self.scheduler_gen = optim.lr_scheduler.StepLR(
            self.opt_gen, step_size=c.lr_step_size, gamma=c.lr_gamma
        )
        self.scheduler_disc = optim.lr_scheduler.StepLR(
            self.opt_disc, step_size=c.lr_step_size, gamma=c.lr_gamma
        )

        # æŸå¤±å‡½æ•°
        self.mse_loss = nn.MSELoss()
        self.bce_loss = nn.BCELoss()

        # æ•°æ®é›†å’ŒåŠ è½½å™¨ï¼ˆWindowsä¸‹num_workers=0é¿å…å¤šè¿›ç¨‹é”™è¯¯ï¼‰
        self.train_dataset = StegoDataset(is_train=True)
        self.val_dataset = StegoDataset(is_train=False)
        self.train_loader = DataLoader(
            self.train_dataset, batch_size=c.batch_size, shuffle=True, num_workers=0
        )
        self.val_loader = DataLoader(
            self.val_dataset, batch_size=c.batchsize_val, shuffle=c.shuffle_val, num_workers=0
        )

        # æ—¥å¿—å’Œæ£€æŸ¥ç‚¹
        self.writer = SummaryWriter(c.LOG_PATH)
        os.makedirs(c.CHECKPOINT_PATH, exist_ok=True)
        os.makedirs(c.IMAGE_PATH, exist_ok=True)  # ç¤ºä¾‹å›¾ç‰‡ä¿å­˜ç›®å½•
        os.makedirs(c.SAMPLE_IMAGE_PATH, exist_ok=True)  # ç¡®ä¿æ ·æœ¬å›¾ç‰‡ç›®å½•å­˜åœ¨
        self.best_psnr = 0.0  # æœ€ä½³éªŒè¯PSNRï¼ˆç§˜å¯†æå–ï¼‰
        self.best_psnr_container = 0.0  # æœ€ä½³éªŒè¯PSNRï¼ˆå®¹å™¨ä¸å®¿ä¸»ï¼‰

    def load_checkpoint(self, checkpoint_path):
        """åŠ è½½æ£€æŸ¥ç‚¹ï¼ˆæœ€ä½³æ¨¡å‹æˆ–æ–­ç‚¹ç»­è®­ï¼‰"""
        if os.path.exists(checkpoint_path):
            try:
                # åŠ è½½æ£€æŸ¥ç‚¹å¹¶æ˜ å°„åˆ°å½“å‰è®¾å¤‡
                checkpoint = torch.load(checkpoint_path, map_location=self.device)
                self.gen.load_state_dict(checkpoint['gen_state_dict'])
                self.disc.load_state_dict(checkpoint['disc_state_dict'])
                # å¯é€‰ï¼šåŠ è½½ä¼˜åŒ–å™¨çŠ¶æ€ï¼ˆæ–­ç‚¹ç»­è®­éœ€è¦ï¼‰
                if 'opt_gen_state_dict' in checkpoint:
                    self.opt_gen.load_state_dict(checkpoint['opt_gen_state_dict'])
                if 'opt_disc_state_dict' in checkpoint:
                    self.opt_disc.load_state_dict(checkpoint['opt_disc_state_dict'])
                # æ¢å¤æœ€ä½³PSNRå’Œèµ·å§‹epoch
                self.best_psnr = checkpoint.get('best_psnr', self.best_psnr)
                start_epoch = checkpoint.get('epoch', 0) + 1  # ä»ä¸‹ä¸€ä¸ªepochå¼€å§‹
                print(f"âœ… åŠ è½½æ£€æŸ¥ç‚¹æˆåŠŸï¼š{checkpoint_path}")
                print(f"  - æ¢å¤åˆ°Epoch: {start_epoch}")
                print(f"  - å†å²æœ€ä½³PSNRï¼ˆç§˜å¯†ï¼‰ï¼š{self.best_psnr:.2f} dB")
                return start_epoch
            except Exception as e:
                raise RuntimeError(f"âŒ åŠ è½½æ£€æŸ¥ç‚¹å¤±è´¥ï¼š{str(e)}")
        else:
            print(f"âŒ æœªæ‰¾åˆ°æ£€æŸ¥ç‚¹ï¼š{checkpoint_path}ï¼Œå°†ä»å¤´å¼€å§‹è®­ç»ƒ")
            return 0

    def save_sample_images(self, epoch=None, num_samples=5):
        """ä¿å­˜ç¤ºä¾‹å›¾ç‰‡ï¼šå®¿ä¸»ã€å®¹å™¨ã€åŸç§˜å¯†ã€æå–çš„ç§˜å¯†"""
        self.gen.eval()
        save_dir = os.path.join(c.SAMPLE_IMAGE_PATH, f"epoch_{epoch}" if epoch else "final")
        os.makedirs(save_dir, exist_ok=True)

        with torch.no_grad():
            # ä¿®æ­£ï¼šStegoDatasetè¿”å›çš„æ˜¯å­—å…¸ï¼Œéœ€ç”¨keyå–å€¼
            for idx, batch in enumerate(self.val_loader):
                if idx >= num_samples:
                    break  # åªä¿å­˜æŒ‡å®šæ•°é‡çš„æ ·æœ¬

                # ä»batchå­—å…¸ä¸­è·å–å®¿ä¸»å’Œç§˜å¯†å›¾åƒ
                host = batch['host'].to(self.device)
                secret = batch['secret'].to(self.device)

                # å‰å‘ä¼ æ’­
                container = self.gen.embed(host, secret)
                extracted_secret = self.gen.extract(container)
                # è½¬æ¢ä¸º[0,1]èŒƒå›´åä¼ å…¥refine_head
                extracted_secret_01 = (extracted_secret + 1) / 2
                extracted_refined = self.refine_head(extracted_secret_01)

                # è½¬æ¢ä¸º[0, 1]èŒƒå›´ï¼ˆé€‚é…å›¾åƒä¿å­˜ï¼‰
                def tensor_to_01(tensor):
                    return (tensor.cpu() + 1) / 2  # ä»[-1,1]è½¬[0,1]

                # å–batchä¸­çš„ç¬¬ä¸€ä¸ªæ ·æœ¬ï¼ˆç»´åº¦ï¼šCÃ—HÃ—Wï¼‰
                host_01 = tensor_to_01(host[0])
                container_01 = tensor_to_01(container[0])
                secret_01 = tensor_to_01(secret[0])
                # refinedæ˜¯[0,1]èŒƒå›´ï¼Œç›´æ¥è½¬æ¢
                extracted_refined_01 = extracted_refined[0].cpu().clamp(0, 1)

                # è½¬æ¢ä¸ºPILå›¾åƒï¼ˆå¤„ç†å•é€šé“/ä¸‰é€šé“ï¼‰
                def pil_convert(tensor):
                    tensor_np = tensor.numpy()
                    if tensor.shape[0] == 1:  # å•é€šé“ï¼ˆç°åº¦å›¾ï¼‰
                        return Image.fromarray((tensor_np.squeeze(0) * 255).astype(np.uint8), mode='L')
                    else:  # ä¸‰é€šé“ï¼ˆRGBå›¾ï¼‰
                        # è½¬æ¢ç»´åº¦ï¼šCÃ—HÃ—W â†’ HÃ—WÃ—C
                        return Image.fromarray((tensor_np.transpose(1, 2, 0) * 255).astype(np.uint8), mode='RGB')

                # ä¿å­˜å•ä¸ªå›¾åƒ
                pil_convert(host_01).save(os.path.join(save_dir, f"sample_{idx+1}_host.png"))
                pil_convert(container_01).save(os.path.join(save_dir, f"sample_{idx+1}_container.png"))
                pil_convert(secret_01).save(os.path.join(save_dir, f"sample_{idx+1}_secret_ori.png"))
                pil_convert(extracted_refined_01).save(os.path.join(save_dir, f"sample_{idx+1}_secret_ext.png"))

                # æ‹¼æ¥å›¾åƒå¹¶ä¿å­˜ï¼ˆæ›´ç›´è§‚å¯¹æ¯”ï¼‰
                fig, axes = plt.subplots(2, 2, figsize=(12, 12))
                axes[0, 0].imshow(pil_convert(host_01))
                axes[0, 0].set_title("Host Image", fontsize=12)
                axes[0, 0].axis('off')

                axes[0, 1].imshow(pil_convert(container_01))
                axes[0, 1].set_title("Container Image", fontsize=12)
                axes[0, 1].axis('off')

                axes[1, 0].imshow(pil_convert(secret_01))
                axes[1, 0].set_title("Original Secret", fontsize=12)
                axes[1, 0].axis('off')

                axes[1, 1].imshow(pil_convert(extracted_refined_01))
                axes[1, 1].set_title("Refined Extracted Secret", fontsize=12)
                axes[1, 1].axis('off')

                plt.tight_layout()
                plt.savefig(os.path.join(save_dir, f"sample_{idx+1}_combined.png"), dpi=300, bbox_inches='tight')
                plt.close()

        print(f"ğŸ“¸ ç¤ºä¾‹å›¾ç‰‡å·²ä¿å­˜è‡³ï¼š{save_dir}")

    def train_one_epoch(self, epoch):
        """è®­ç»ƒå•ä¸ªEpoch"""
        self.gen.train()
        self.disc.train()
        total_loss_gen = 0.0
        total_loss_disc = 0.0

        pbar = tqdm(self.train_loader, desc=f"Epoch {epoch + 1}/{c.epochs}")
        # ä¿®æ­£ï¼šStegoDatasetè¿”å›çš„æ˜¯å­—å…¸ï¼Œéœ€éå†batchå­—å…¸
        for batch in pbar:
            # ä»batchå­—å…¸ä¸­è·å–å®¿ä¸»å’Œç§˜å¯†å›¾åƒ
            host = batch['host'].to(self.device)
            secret = batch['secret'].to(self.device)
            batch_size = host.shape[0]

            # -------------------- è®­ç»ƒåˆ¤åˆ«å™¨ï¼ˆå¤šè½®è®­ç»ƒå¢å¼ºå¯¹æŠ—å‹åŠ›ï¼‰ --------------------
            # åˆ¤åˆ«å™¨è®­ç»ƒ2æ¬¡ï¼Œç”Ÿæˆå™¨1æ¬¡ï¼ˆè§£å†³åˆ¤åˆ«å™¨è®­ç»ƒä¸è¶³çš„é—®é¢˜ï¼‰
            for _ in range(2):
                self.opt_disc.zero_grad()
                # ç”Ÿæˆå®¹å™¨å›¾åƒï¼ˆ-1~1èŒƒå›´ï¼‰
                with torch.no_grad():  # åˆ¤åˆ«å™¨è®­ç»ƒæ—¶ï¼Œç”Ÿæˆå™¨ä¸è®¡ç®—æ¢¯åº¦
                    container = self.gen.embed(host, secret)
                # è½¬æ¢ä¸º[0,1]èŒƒå›´ï¼ˆé€‚é…æ”»å‡»ã€åˆ¤åˆ«å™¨ã€æŒ‡æ ‡è®¡ç®—ï¼‰
                container_01 = (container + 1) / 2
                host_01 = (host + 1) / 2

                # åˆ¤åˆ«å™¨æ ‡ç­¾ï¼ˆçœŸå®=1ï¼Œç”Ÿæˆ=0ï¼‰
                real_label = torch.ones(batch_size, device=self.device)
                fake_label = torch.zeros(batch_size, device=self.device)

                # åˆ¤åˆ«å™¨æŸå¤±ï¼šä½¿ç”¨Main.Discriminatorçš„get_scoreæ–¹æ³•ï¼ˆè¿”å›1ç»´ï¼‰
                loss_real = self.bce_loss(self.disc.get_score(host_01), real_label)
                loss_fake = self.bce_loss(self.disc.get_score(container_01.detach()), fake_label)
                loss_disc = (loss_real + loss_fake) * 0.5

                # åå‘ä¼ æ’­+ä¼˜åŒ–
                loss_disc.backward()
                self.opt_disc.step()
                total_loss_disc += loss_disc.item() / 2  # å¹³å‡åˆ°2æ¬¡è®­ç»ƒ

            # -------------------- è®­ç»ƒç”Ÿæˆå™¨ --------------------
            self.opt_gen.zero_grad()
            # é‡æ–°ç”Ÿæˆå®¹å™¨ï¼ˆç”Ÿæˆå™¨è®­ç»ƒæ—¶ï¼Œéœ€è¦è®¡ç®—æ¢¯åº¦ï¼‰
            container = self.gen.embed(host, secret)
            # è½¬æ¢ä¸º[0,1]èŒƒå›´ï¼ˆé€‚é…æ”»å‡»ã€åˆ¤åˆ«å™¨ã€æŒ‡æ ‡è®¡ç®—ï¼‰
            container_01 = (container + 1) / 2
            host_01 = (host + 1) / 2
            # ä¿ç•™æ¢¯åº¦ï¼ˆæ”»å‡»éœ€è¦ï¼‰
            container_01.requires_grad_(True)  # æ˜¾å¼å¼€å¯æ¢¯åº¦

            # 1. ç”Ÿæˆå¼è¯¯å·®é¢„åˆ¤ï¼šç”¨é¢„æµ‹è¯¯å·®ä¿®æ­£å®¹å™¨å›¾åƒï¼ˆä¼˜åŒ–åˆ›æ–°ç‚¹3ï¼‰
            pred_error_total = None
            if self.training:
                # è§£åŒ…è¿”å›çš„å…ƒç»„ï¼Œåªå–æ€»è¯¯å·®ï¼ˆç¬¬ä¸€ä¸ªå€¼ï¼‰
                pred_error_total, _, _, _ = self.error_predictor(container)
                # ç”¨æ€»è¯¯å·®è¿›è¡Œä¿®æ­£ï¼ˆä¿æŒ-1~1èŒƒå›´ï¼‰
                container = container - c.error_correction_weight * pred_error_total
                container = torch.clamp(container, -1.0, 1.0)  # é™åˆ¶èŒƒå›´ï¼Œé¿å…æº¢å‡º
                # é‡æ–°è½¬æ¢ä¸º[0,1]ï¼ˆä¿®æ­£åï¼‰
                container_01 = (container + 1) / 2
                container_01.requires_grad_(True)  # é‡æ–°å¼€å¯æ¢¯åº¦

            # 2. å¯¹æŠ—æ”»å‡»ï¼ˆéšæœºé€‰æ‹©æ”»å‡»ç±»å‹ï¼‰
            attack_type = np.random.choice(c.supported_attacks)
            container_attacked_01 = None
            if attack_type in ['fgsm', 'pgd']:
                # å¯¹æŠ—æ”»å‡»éœ€è¦æ¢¯åº¦ï¼Œå…ˆè®¡ç®—åˆ¤åˆ«å™¨çš„é¢„æµ‹å€¼
                pred_4d = self.disc(container_01)  # 4ç»´å¼ é‡ï¼š(batch, 1, h, w)
                # è®¡ç®—ä¸´æ—¶GANæŸå¤±ä»¥è·å–æ¢¯åº¦
                loss_gan_temp = self.bce_loss(pred_4d.mean(dim=[1, 2, 3]), torch.ones(batch_size, device=self.device))
                # åå‘ä¼ æ’­è·å–æ¢¯åº¦ï¼ˆä»…è®¡ç®—container_01çš„æ¢¯åº¦ï¼‰
                self.gen.zero_grad()
                self.disc.zero_grad()
                loss_gan_temp.backward(retain_graph=True)
                # å®‰å…¨è·å–æ¢¯åº¦ï¼ˆé¿å…æ¢¯åº¦ä¸ºNoneï¼‰
                container_grad = container_01.grad.detach() if container_01.grad is not None else torch.zeros_like(container_01)
                # æ‰§è¡Œæ”»å‡»
                container_attacked_01 = attack_image(container_01, attack_type, container_grad, c.epsilon)
                # æ¸…ç©ºæ¢¯åº¦ï¼Œé¿å…æ®‹ç•™
                container_01.grad.zero_()
            else:
                # éå¯¹æŠ—æ”»å‡»ï¼Œç›´æ¥è°ƒç”¨
                container_attacked_01 = attack_image(container_01, attack_type)

            # è½¬æ¢å›[-1,1]èŒƒå›´ï¼Œé€‚é…ç”Ÿæˆå™¨æå–
            container_attacked = (container_attacked_01 * 2) - 1

            # 3. æå–å¹¶ä¿®å¤ç§˜å¯†
            extracted_secret = self.gen.extract(container_attacked)
            # è½¬æ¢ä¸º[0,1]èŒƒå›´åä¼ å…¥refine_headï¼ˆåŒ¹é…Mainçš„refine_headé¢„æœŸï¼‰
            extracted_secret_01 = (extracted_secret + 1) / 2
            extracted_secret_refined = self.refine_head(extracted_secret_01)  # refine_headè¾“å‡º[0,1]

            # 4. åŠ¨æ€æƒé‡è°ƒæ•´ï¼ˆä¿®å¤é”®ä¸åŒ¹é…é—®é¢˜ï¼‰
            texture_complexity = self.pzms_extractor.get_texture_complexity(host)
            # è½¬æ¢ä¸º[0,1]èŒƒå›´ï¼ˆæŸå¤±è®¡ç®—ï¼‰
            secret_01 = (secret + 1) / 2
            # è®¡ç®—åŸºç¡€æŸå¤±ï¼ˆé”®æ”¹ä¸ºcap/rob/impï¼ŒåŒ¹é…weight_balancerï¼‰
            loss_capacity = self.mse_loss(extracted_secret_refined, secret_01)  # refinedå·²æ˜¯[0,1]
            loss_imperceptible = 1 - SSIM(container_01, host_01)  # ä¸å¯æ„ŸçŸ¥æ€§æŸå¤±ï¼ˆSSIMè¶Šå°ï¼ŒæŸå¤±è¶Šå¤§ï¼‰
            loss_robustness = self.mse_loss(extracted_secret_01, extracted_secret_refined)  # é²æ£’æ€§æŸå¤±

            # æ”¶é›†å½“å‰æŸå¤±å€¼ï¼ˆé”®åŒ¹é…ï¼‰
            current_losses = {
                'cap': loss_capacity.item(),
                'rob': loss_robustness.item(),
                'imp': loss_imperceptible.item()
            }
            # åŠ¨æ€è°ƒæ•´æƒé‡
            cap_w, rob_w, imp_w = self.weight_balancer.adjust(texture_complexity, attack_type, current_losses)

            # 5. æŸå¤±è®¡ç®—
            # è¯¯å·®é¢„æµ‹æŸå¤±ï¼ˆç¡®ä¿pred_error_totalä¸ä¸ºNoneï¼‰
            if pred_error_total is None:
                pred_error_total, _, _, _ = self.error_predictor(container)
            pred_error_01 = (pred_error_total + 1) / 2  # è½¬æ¢ä¸º[0,1]ï¼ŒåŒ¹é…å®¹å™¨èŒƒå›´
            loss_error = self.mse_loss(pred_error_01, torch.zeros_like(container_01))  # é¢„æµ‹è¯¯å·®è¶Šå°è¶Šå¥½

            # GANæŸå¤±ï¼šä½¿ç”¨get_scoreæ–¹æ³•ï¼ˆè¿”å›1ç»´ï¼ŒåŒ¹é…BCEæŸå¤±ï¼‰
            loss_gan = self.bce_loss(self.disc.get_score(container_01), torch.ones(batch_size, device=self.device))

            # ç‰¹å¾åŒ¹é…æŸå¤±ï¼ˆå¢å¼ºå¤šåŸŸé—­ç¯èåˆï¼‰
            disc_features_real = self.disc.get_intermediate_features(host_01)
            disc_features_fake = self.disc.get_intermediate_features(container_01)
            loss_feat_match = self.mse_loss(disc_features_fake, disc_features_real.detach())

            # æ€»æŸå¤±ï¼ˆåŠ æƒæ±‚å’Œï¼‰
            loss_gen = (
                cap_w * loss_capacity +
                rob_w * loss_robustness +
                imp_w * loss_imperceptible +
                c.gan_weight * loss_gan +
                c.error_pred_weight * loss_error +
                c.feat_match_weight * loss_feat_match
            )

            # åå‘ä¼ æ’­+ä¼˜åŒ–
            loss_gen.backward()
            self.opt_gen.step()
            total_loss_gen += loss_gen.item()

            # æ›´æ–°è¿›åº¦æ¡
            pbar.set_postfix({
                "Gen Loss": f"{loss_gen.item():.4f}",
                "Disc Loss": f"{loss_disc.item():.4f}"
            })

        # å¹³å‡æŸå¤±ï¼ˆé™¤ä»¥è¿­ä»£æ¬¡æ•°ï¼‰
        avg_loss_gen = total_loss_gen / len(self.train_loader)
        avg_loss_disc = total_loss_disc / len(self.train_loader)
        # è®°å½•æ—¥å¿—
        self.writer.add_scalar("Train/Gen_Loss", avg_loss_gen, epoch)
        self.writer.add_scalar("Train/Disc_Loss", avg_loss_disc, epoch)
        print(f"\nEpoch {epoch + 1} | Gen Loss: {avg_loss_gen:.4f} | Disc Loss: {avg_loss_disc:.4f}")

        # æ›´æ–°å­¦ä¹ ç‡
        self.scheduler_gen.step()
        self.scheduler_disc.step()

    def validate(self, epoch):
        """éªŒè¯é˜¶æ®µï¼šè®¡ç®—PSNR/SSIMå¹¶ä¿å­˜æœ€ä½³æ¨¡å‹"""
        self.gen.eval()
        total_psnr_secret = 0.0  # ç§˜å¯†æå–çš„PSNR
        total_ssim_secret = 0.0  # ç§˜å¯†æå–çš„SSIM
        total_psnr_container = 0.0  # å®¹å™¨ä¸å®¿ä¸»çš„PSNRï¼ˆä¸å¯æ„ŸçŸ¥æ€§ï¼‰
        total_ssim_container = 0.0  # å®¹å™¨ä¸å®¿ä¸»çš„SSIMï¼ˆä¸å¯æ„ŸçŸ¥æ€§ï¼‰

        with torch.no_grad():
            # ä¿®æ­£ï¼šStegoDatasetè¿”å›çš„æ˜¯å­—å…¸ï¼Œéœ€éå†batchå­—å…¸
            for batch in self.val_loader:
                host = batch['host'].to(self.device)
                secret = batch['secret'].to(self.device)

                # ç”Ÿæˆå®¹å™¨å¹¶æå–ç§˜å¯†
                container = self.gen.embed(host, secret)
                # è½¬æ¢ä¸º[0,1]èŒƒå›´ï¼ˆé€‚é…æŒ‡æ ‡è®¡ç®—ï¼‰
                container_01 = (container + 1) / 2
                host_01 = (host + 1) / 2
                secret_01 = (secret + 1) / 2

                # æå–å¹¶ä¿®å¤ç§˜å¯†
                extracted_secret = self.gen.extract(container)
                extracted_secret_01 = (extracted_secret + 1) / 2
                extracted_refined = self.refine_head(extracted_secret_01)  # ä¿®å¤åçš„ç§˜å¯†

                # è®¡ç®—æŒ‡æ ‡ï¼šç§˜å¯†æå–ï¼ˆæ ¸å¿ƒæŒ‡æ ‡ï¼‰
                total_psnr_secret += PSNR(extracted_refined, secret_01)
                total_ssim_secret += SSIM(extracted_refined, secret_01).item()
                # è®¡ç®—æŒ‡æ ‡ï¼šå®¹å™¨ä¸å®¿ä¸»ï¼ˆä¸å¯æ„ŸçŸ¥æ€§ï¼Œæ–°å¢ï¼‰
                total_psnr_container += PSNR(container_01, host_01)
                total_ssim_container += SSIM(container_01, host_01).item()

        # å¹³å‡æŒ‡æ ‡ï¼ˆé™¤ä»¥éªŒè¯é›†è¿­ä»£æ¬¡æ•°ï¼‰
        avg_psnr_secret = total_psnr_secret / len(self.val_loader)
        avg_ssim_secret = total_ssim_secret / len(self.val_loader)
        avg_psnr_container = total_psnr_container / len(self.val_loader)
        avg_ssim_container = total_ssim_container / len(self.val_loader)

        # è®°å½•æ—¥å¿—
        self.writer.add_scalar("Val/PSNR_Secret", avg_psnr_secret, epoch)
        self.writer.add_scalar("Val/SSIM_Secret", avg_ssim_secret, epoch)
        self.writer.add_scalar("Val/PSNR_Container", avg_psnr_container, epoch)
        self.writer.add_scalar("Val/SSIM_Container", avg_ssim_container, epoch)

        # æ‰“å°ç»“æœ
        print(f"\nğŸ“Š Validation Results:")
        print(f"  - Secret: PSNR = {avg_psnr_secret:.2f} dB | SSIM = {avg_ssim_secret:.4f}")
        print(f"  - Container: PSNR = {avg_psnr_container:.2f} dB | SSIM = {avg_ssim_container:.4f}")

        # ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ˆä»¥ç§˜å¯†æå–çš„PSNRä¸ºæ ¸å¿ƒæŒ‡æ ‡ï¼‰
        if avg_psnr_secret > self.best_psnr:
            self.best_psnr = avg_psnr_secret
            self.best_psnr_container = avg_psnr_container
            # ä¿å­˜æ£€æŸ¥ç‚¹ï¼ˆåŒ…å«ä¼˜åŒ–å™¨çŠ¶æ€ï¼Œæ”¯æŒæ–­ç‚¹ç»­è®­ï¼‰
            checkpoint_path = os.pathã€‚join(c.CHECKPOINT_PATH, "best_model.pth")
            torch.save({
                "gen_state_dict": self.genã€‚state_dict()ï¼Œ
                "disc_state_dict": self.discã€‚state_dict()ï¼Œ
                "opt_gen_state_dict": self.opt_gen.state_dict(),
                "opt_disc_state_dict": self.opt_disc.state_dict(),
                "epoch": epoch,
                "best_psnr": self.best_psnrï¼Œ
                "best_psnr_container": self.best_psnr_container
            }, checkpoint_path)
            print(f"âœ… ä¿å­˜æœ€ä½³æ¨¡å‹ï¼ˆSecret PSNR: {avg_psnr_secret:.2f} dBï¼‰")

        return avg_psnr_secret  # è¿”å›PSNRç”¨äºæ—©åœåˆ¤æ–­

    def run(self):
        """å¯åŠ¨è®­ç»ƒæµç¨‹ï¼ˆå«æ—©åœã€æ–­ç‚¹ç»­è®­ã€å›¾ç‰‡ä¿å­˜ï¼‰"""
        # æ­¥éª¤1ï¼šåŠ è½½æœ€ä½³æ¨¡å‹ï¼ˆç¬¬äºŒæ¬¡è®­ç»ƒæ—¶è‡ªåŠ¨ä½¿ç”¨ï¼‰
        start_epoch = self.load_checkpoint(os.path.join(c.CHECKPOINT_PATH, "best_model.pth"))

        # æ­¥éª¤2ï¼šåˆå§‹åŒ–æ—©åœå‚æ•°
        no_improve_epochs = 0
        early_stop_triggered = False

        # æ­¥éª¤3ï¼šå¼€å§‹è®­ç»ƒ
        for epoch in range(start_epoch, c.epochs):
            # è®­ç»ƒå•ä¸ªepoch
            self.train_one_epoch(epoch)

            # éªŒè¯+ä¿å­˜ç¤ºä¾‹å›¾ç‰‡ï¼ˆæŒ‰éªŒè¯é¢‘ç‡æ‰§è¡Œï¼‰
            if (epoch + 1) % c.val_freq == 0:
                avg_psnr = self.validate(epoch)
                # ä¿å­˜ç¤ºä¾‹å›¾ç‰‡
                self.save_sample_images(epoch=epoch+1)

                # æ—©åœåˆ¤æ–­ï¼ˆæ ¸å¿ƒæŒ‡æ ‡ï¼šç§˜å¯†æå–çš„PSNRï¼‰
                if avg_psnr > self.best_psnr:
                    no_improve_epochs = 0  # é‡ç½®è®¡æ•°å™¨
                else:
                    no_improve_epochs += 1
                    print(f"âš ï¸  éªŒè¯PSNRè¿ç»­{no_improve_epochs}è½®æœªæå‡ï¼ˆè€å¿ƒï¼š{c.early_stop_patience}ï¼‰")
                    if no_improve_epochs >= c.early_stop_patience:
                        print(f"ğŸ›‘ æ—©åœè§¦å‘ï¼Œåœæ­¢è®­ç»ƒï¼ˆEpoch: {epoch+1}ï¼‰")
                        early_stop_triggered = True
                        break

            # ä¿å­˜æ–­ç‚¹ï¼ˆæŒ‰ä¿å­˜é¢‘ç‡æ‰§è¡Œï¼Œä¸”æœªè§¦å‘æ—©åœï¼‰
            if (epoch + 1) % c.save_freq == 0 and not early_stop_triggered:
                checkpoint_path = os.pathã€‚join(c.CHECKPOINT_PATH, f"model_epoch_{epoch + 1}.pth")
                torch.save({
                    "gen_state_dict": self.gen.state_dict(),
                    "disc_state_dict": self.disc.state_dict(),
                    "opt_gen_state_dict": self.opt_gen.state_dict(),
                    "opt_disc_state_dict": self.opt_disc.state_dict(),
                    "epoch": epoch,
                    "best_psnr": self.best_psnr
                }, checkpoint_path)
                print(f"ğŸ’¾ ä¿å­˜æ–­ç‚¹æ¨¡å‹ï¼šmodel_epoch_{epoch+1}.pth")

        # è®­ç»ƒç»“æŸåä¿å­˜æœ€ç»ˆç¤ºä¾‹å›¾ç‰‡
        if not early_stop_triggered:
            self.save_sample_images()  # ä¿å­˜finalç‰ˆæœ¬

        # å…³é—­æ—¥å¿—å†™å…¥å™¨ï¼ˆä¿®æ­£ä¸­æ–‡æ ‡ç‚¹ï¼‰
        self.writer.close()
        print("\nğŸ‰ è®­ç»ƒæµç¨‹å®Œæˆï¼")

if __name__ == "__main__":
    # å®ä¾‹åŒ–å¹¶å¯åŠ¨è®­ç»ƒ
    trainer = Trainer()
    trainer.run()
